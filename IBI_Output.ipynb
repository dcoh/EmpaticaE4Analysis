{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from decimal import Decimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_path = r'/Users/dancohen/Dropbox/E4 stuff/test data/EDA_All_Data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function that returns a list of floats iterated upwards by sample rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_sample_rate(df_length, fs):\n",
    "    # returns list of floats starting from zero iterated upward by sample rate\n",
    "    result = []\n",
    "    curr_time = 0.0\n",
    "    result.append(curr_time)\n",
    "    \n",
    "    for i in range(df_length-1):\n",
    "        curr_time += 1.0/fs\n",
    "        result.append(curr_time)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_path = r'/Users/dancohen/Dropbox/E4 stuff/test data'\n",
    "output_path = r'/Users/dancohen/Dropbox/E4 stuff/test data/IBI_All_Data'\n",
    "all_folders = glob.glob(file_path + \"/PRF*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function that finds the number of seconds differenc between (t_0, a unix timestamp) and a datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_0_diff_seconds(t_0, date_time):\n",
    "    return (date_time - pd.to_datetime(t_0, unit='s', infer_datetime_format = True)).total_seconds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function that takes a dataframe with a column in seconds and normalizes the values in that column to start at 0.00 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_df(start_df, col_label):\n",
    "    #Make a copy here to prevent chaining assignment in the dataframe\n",
    "    start_seconds = start_df.iloc[0][0]\n",
    "    cp = start_df.copy()\n",
    "    cp[col_label] = start_df.apply(lambda x: x[col_label]-start_seconds, axis=1)\n",
    "    cp = cp.reset_index(drop=True)\n",
    "    #cp = cp.set_index(col_label)\n",
    "    return cp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function to calculate summary stats for IBI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ibi_sum_stats(data_col, part_id):\n",
    "    nn_50 = np.sum(np.abs(np.diff(data_col)) > 0.05)*1\n",
    "    rmssd = np.sqrt(np.mean(np.square(np.diff(data_col))))\n",
    "    sdnn = np.std(data_col)\n",
    "    stats = {part_id: [nn_50, rmssd, sdnn]}\n",
    "    names = ['NN50', 'RMSSD', 'SDNN']\n",
    "    df = pd.DataFrame(stats)\n",
    "    df['stats'] = names\n",
    "    df = df.set_index('stats')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred parsing tags.csv for PRF020.  Error: 'the label [6] is not in the [index]'. This file will be skipped.\n"
     ]
    }
   ],
   "source": [
    "ibi_list = []\n",
    "st_1_2 = []\n",
    "ibi_1_2 = []\n",
    "st_2_3 = []\n",
    "ibi_2_3 = []\n",
    "st_3_end = []\n",
    "ibi_3_end = []\n",
    "\n",
    "for folder in all_folders:\n",
    "    spl = folder.split('/')\n",
    "    \n",
    "    #Folder names are 'PRF###' (participant ID) and we are interested in the ID\n",
    "    part_id = spl[len(spl)-1][3:]\n",
    "    \n",
    "    # Grab the csv containing the timestamps that mark the start and end times of the scripts\n",
    "    script_times = pd.read_csv(folder+\"/tags.csv\", header=None)\n",
    "    script_times = script_times.apply(lambda x: pd.to_datetime(x, unit='s'))\n",
    "\n",
    "        \n",
    "    ibi_df_raw = pd.read_csv(folder+\"/IBI.csv\")\n",
    "    starting_timestamp = ibi_df_raw.columns[0]\n",
    "    \n",
    "    try:\n",
    "        begin_s1 = t_0_diff_seconds(starting_timestamp, script_times.loc[1].iat[0])\n",
    "        end_s1 = t_0_diff_seconds(starting_timestamp, script_times.loc[2].iat[0])\n",
    "        \n",
    "        begin_s2 = t_0_diff_seconds(starting_timestamp, script_times.loc[3].iat[0])    \n",
    "        end_s2 = t_0_diff_seconds(starting_timestamp, script_times.loc[4].iat[0])\n",
    "\n",
    "        begin_s3 = t_0_diff_seconds(starting_timestamp, script_times.loc[5].iat[0])\n",
    "        end_s3 = t_0_diff_seconds(starting_timestamp, script_times.loc[6].iat[0])\n",
    "    except Exception as err:\n",
    "        print(\"Error occurred parsing tags.csv for PRF{}.  Error: {}. This file will be skipped.\".format(part_id, err))\n",
    "        continue\n",
    "    \n",
    "    start_seconds = ibi_df_raw.loc[0].iat[0]\n",
    "    #Normalize T0 down to 0 for the rest of the column.  This will make plotting data against each other easier later\n",
    "    normalized_time = ibi_df_raw[starting_timestamp].apply(lambda x: x-start_seconds)\n",
    "\n",
    "    ibi_df_raw[starting_timestamp] = normalized_time\n",
    "    \n",
    "    ibi_df = ibi_df_raw.rename(columns={starting_timestamp: \"Time_After_T0\", \" IBI\":part_id})\n",
    "    \n",
    "    df_1_2 = ibi_df[(ibi_df['Time_After_T0'] >= end_s1) & (ibi_df['Time_After_T0'] < begin_s2)]\n",
    "    df_2_3 = ibi_df[(ibi_df['Time_After_T0'] >= end_s2) & (ibi_df['Time_After_T0'] < begin_s3)]\n",
    "    df_3_end = ibi_df[(ibi_df['Time_After_T0'] >= end_s3)]\n",
    "    \n",
    "    #Normalize each frame's timestamp down to 0.00 seconds once we know where the timing cutoffs for each frame are\n",
    "    #See lines above\n",
    "    norm_1_2 = df_1_2.iloc[0][1]\n",
    "    cp_1_2 = normalize_df(df_1_2, 'Time_After_T0')\n",
    "    stat_1_2 = ibi_sum_stats(cp_1_2[part_id], part_id)\n",
    "    cp_1_2 = cp_1_2.transpose()\n",
    "    st_1_2.append(stat_1_2)\n",
    "    \n",
    "    norm_2_3 = df_2_3.iloc[0][1]\n",
    "    cp_2_3 = normalize_df(df_2_3, 'Time_After_T0')\n",
    "    stat_2_3 = ibi_sum_stats(cp_2_3[part_id], part_id)\n",
    "    st_2_3.append(stat_2_3)\n",
    "    cp_2_3 = cp_2_3.transpose()\n",
    "    \n",
    "    norm_3_end = df_3_end.iloc[0][1]\n",
    "    cp_3_end  = normalize_df(df_3_end, 'Time_After_T0')\n",
    "    stat_3_end = ibi_sum_stats(cp_3_end[part_id], part_id)\n",
    "    st_3_end.append(stat_3_end)\n",
    "    cp_3_end = cp_3_end.transpose()\n",
    "    \n",
    "    ibi_1_2.append(cp_1_2)\n",
    "    ibi_2_3.append(cp_2_3)\n",
    "    ibi_3_end.append(cp_3_end)\n",
    "    ibi_list.append(ibi_df.transpose())\n",
    "    \n",
    "    #plt.figure(figsize=(30, 7))\n",
    "    #plt.plot(ibi_df['Time_After_T0'], ibi_df[part_id] )\n",
    "    #plt.title(\"PRF{}\".format(part_id))\n",
    "    #plt.ylabel('IBI')\n",
    "    #plt.xlabel('Time After T0')\n",
    "    #plt.savefig(output_path+\"/IBI{}.pdf\".format(part_id))\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_2 = pd.concat(ibi_1_2)\n",
    "stats_1_2 = pd.concat(st_1_2, axis=1)\n",
    "df_2_3 = pd.concat(ibi_2_3)\n",
    "stats_2_3 = pd.concat(st_2_3, axis=1)\n",
    "df_3_end = pd.concat(ibi_3_end)\n",
    "stats_3_end = pd.concat(st_3_end, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_1_2.to_csv(output_path+\"/IBI_1_2.csv\", float_format='%.6f')\n",
    "df_2_3.to_csv(output_path+\"/IBI_2_3.csv\", float_format='%.6f')\n",
    "df_3_end.to_csv(output_path+\"/IBI_3_end.csv\", float_format='%.6f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stats_1_2.to_csv(output_path+\"/stats_1_2.csv\", float_format='%.6f')\n",
    "stats_2_3.to_csv(output_path+\"/stats_2_3.csv\", float_format='%.6f')\n",
    "stats_3_end.to_csv(output_path+\"/stats_3_end.csv\", float_format='%.6f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(ibi_list)\n",
    "df = df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_path+\"/IBI_All_Participants.csv\", float_format='%.6f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
